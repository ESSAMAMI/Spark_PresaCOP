###  📝 PROJET SPARK STREAMING: PRESACOP
###  👩🏽‍💻 👨🏽‍💻 ***Membres***

	:raising_hand: IHOULINE Inès
    :raising_hand: AKRICHE Lakri
	:bow: ESSAMAMI Hamza


### 🚦 ***Livrables***

GitHUB => `https://github.com/ESSAMAMI/Spark_PresaCOP`

WeTransfer => `https://we.tl/t-cOxHQa6wzK`

### 🚧 ***Sujet***

**PresaCop**, une société spécialisée dans la prestation de services aux forces de police, souhaite
créer un service de drones pour aider les systèmes de police à établir des contraventions de stationnement.
Une caméra équipée d'un logiciel de reconnaissance des formes identifie les plaques d'immatriculation et
caractérise les infractions.
**PresaCop** dispose d'équipes pour développer le drone et travaille effectivement. Le premier prototype est
fini il peut qualifier une infraction. Toutefois, le service **PresaCop** est assorti d'une
logiciel comme une offre de service que PresaCop s'efforce de créer.

### 🧱 ***Architecture***
Le streaming a été mis en place à l'aide de **SparkSCALA avec (DOCKER et KAFKA)**.
Il est important avant de commencer par installer docker. Ensuite se positionner dans le dossier à la racine du projet /***apache_kafka*** et de lancer la comande `> docker-compose up -d` à noter que le `docker.yml` est déjà disponible dans le répertoire courant.

###  📌 ***Questions préliminaires***

- **What technical/business constraints should the architecture meet to fulfill the
    requirement described by the customer in paragraph « Statistics» ? (In other words
    the customer has express some needs, some existing solutions, it comes with
    limitations).
    So what kind of component(s) (listed in the lecture) will the architecture need?**

>   The first constraint that the architecture of the solution will have to take into account is the memory generated by the drones. Indeed, each UAV should produce more than 100 Gb of data per day.
    We can also identify a second constraint, the fact that PresaCop wants to keep each message generated by the drones. Therefore it is necessary to implement an adequate solution to facilitate the archiving of data.
    To manage the above constraints, we will need to set up streaming. Indeed, if the recovered data are only used to make statistics, it's useless to store everything, we can directly make real time analysis with the streaming.
    To have an architecture that meets the different criteria, you have to recover the logs generated by the drones (they become Data Producers), set up a storage server **DOCKER/KAFKA** that will recover the data then divide the data into batches and process them with spark streaming.

- **Same question with the paragraph «Alert».**

>   The architecture of the solution will have to take into account the fact that it is possible that a particular and rare event may be triggered (1% of observed violations), this event requires a human takeover to enter the right violation code.
    To manage these constraints, it will be necessary to reserve a specific storage location where all the data for which the UAV does not know how to qualify the violation will be stored, it will then be processed by a police officer and sent back into the stream.

- **What mistake(s) from Presacop can explains the failed attempt?**

>   The company made a few mistakes that explain its first failure. Indeed, they wanted to send the NYPD data to PresaCop's computers without fully respecting the technical constraints, especially in terms of memory. **It is important to set up a solid architecture before starting**.

- **Presacop has likely forgot some technical information in the regular message sent
    by the drone. In the future this information could help Presacop make its product
    much more profitable. Which information?**

>   To make the Presacop product more profitable, it would be interesting to add a status field to know if a police officer has modified the violation code. Indeed, this information could give us interesting statistics, we could then know how much human intervention is necessary for the solution to be functional, and try to reduce this part as much as possible in the future.
